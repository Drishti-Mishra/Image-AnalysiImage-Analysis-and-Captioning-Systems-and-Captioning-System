# Image-analysis-and-captioning
This repository contains the code for an image captioning model using the VisionEncoderDecoderModel from the transformers library, specifically the ViT-GPT2 model. The model is trained to generate descriptive captions for images.


## ðŸ§ª How to Run the Project

1. **Clone the repo**
```bash
git clone https://github.com/Drishti-Mishra/Image-Analysis-and-Captioning-System.git
cd Image_caption-main

env\Scripts\activate     # For Windows
# OR
source env/bin/activate  # For Linux/macOS

pip install -r requirements.txt

streamlit run app.py

uvicorn api:app --host 127.0.0.1 --port 8000

Image_caption-main/
â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ api.py # FastAPI backend
â”œâ”€â”€ model/ # Pretrained or trained model files
â”œâ”€â”€ env/ # Python virtual environment
â”œâ”€â”€ utils/ # Image processing and helper functions
â”œâ”€â”€ data/ # Sample images or Kaggle dataset
â””â”€â”€ requirements.txt # Python dependencies




